<!DOCTYPE html>
<html>
<head>
    <title></title>
    <meta charset="utf-8" />
    
    <style>
        
    </style>
    
    <script src="https://d3js.org/d3.v4.min.js"></script>

</head>

<body>

    <h1>TD</h1>

    <h2>Value computation example</h2>
    <p>No GUI yet, see javascript</p>

    <h2>Estimating from data</h2>

    <p>gamma = 1, so is not inserted into formula</p>

    <p>Ep 1</p>
    <ul>
        <li>V(s0) = 1 + Avg[V(s2)] = 2</li>
        <li>V(s2) = 0 + Avg[V(s3)] = 1</li>
        <li>V(s3) = 1 + Avg[V(s5)] = 1</li>
        <li>V(s5) = 0</li>
    </ul>

    <p>Ep 2</p>
    <ul>
        <li>V(s0) = 1 + Avg[V(s2) + V'(s2)]
                  = 1 + (10 + 1) / 2 = 6.5</li>
        <li>V(s2) = 0 + Avg[V(s4)] = 10</li>
        <li>V(s4) = 10 + Avg[V(s5)] = 10</li>
        <li>V(s5) = 0</li>
    </ul>

    <p>Ep 3</p>
    <ul>
        <li>V(s0) = 1 + Avg[V(s2)]
                  = 1 + (1 + 10 + 1) / 3 = 5</li>
        <li>V(s2) = 0 + Avg[V(s3)]
                  = 0 + (1 + 1) / 2 = 1</li>
        <li>V(s3) = 1 + Avg[V(s5)] = 1</li>
        <li>V(s5) = 0</li>
    </ul>

    <h2>Computing Estimates Incrementally</h2>
    
    <p>We know V<sub>t-1</sub>(s<sub>1</sub>)</p>
    <p>We know R<sub>t</sub>(s<sub>1</sub>)</p>
    <p>In order to compute V<sub>t</sub>(s<sub>1</sub>) we can do:</p>

    <p>V<sub>t</sub>(s<sub>1</sub>) = 
        [(t - 1) V<sub>t-1</sub>(s<sub>1</sub>) + 
        R<sub>t</sub>(s<sub>1</sub>) ] / t
        = V<sub>t-1</sub>(s<sub>1</sub>) + 
        (1 / t) * (R<sub>t</sub>(s<sub>1</sub>)
                            - V<sub>t-1</sub>(s<sub>1</sub>))</p>
    
    <p>(R<sub>t</sub>(s<sub>1</sub>)
        - V<sub>t-1</sub>(s<sub>1</sub>)) is the error</p>
    <p>(1 / t) = &alpha;<sub>t</sub> is the learning rate</p>

    <h2>TD(1) rule</h2>
    <p>Compute V(s<sub>t</sub>) based on episodes with S<sub>t</sub></p>
    <p>If we estimate the maximum likelihood instead we use all information
        that we have.
    </p>

    <h2>TD(0) rule</h2>
    <p>Epoch T</p>
    <p>V<sub>T</sub>(s<sub>t-1</sub>) = V<sub>T</sub>(s<sub>t-1</sub>) 
        + &alpha;<sub>T</sub> 
        (r<sub>t</sub> + &gamma; V<sub>T</sub>(s<sub>t</sub>) 
        - V<sub>T</sub>(s<sub>t-1</sub>))</p>
        
<script>

let dataset = {
    nodes: [],
    edges: [
        { source: 0, target: 2, reward: 1, prob: 1},
        { source: 1, target: 2, reward: 2, prob: 1},
        { source: 2, target: 3, reward: 0, prob: .9},
        { source: 2, target: 4, reward: 0, prob: .1},
        { source: 3, target: 5, reward: 1, prob: 1},
        { source: 4, target: 5, reward: 10, prob: 1}
    ]
}

let counterId = 0;
let totalStates = 6
for (let i = 0; i < totalStates; i++) {
    dataset.nodes.push({ id: counterId++});
}

let finalStateId = counterId - 1;
let gamma = 1;

estimateValueOfAllStates();

// inefficient computation, doesn't reuse the previous computation
function estimateValueOfAllStates() {
    for (let s = 0; s < dataset.nodes.length; s++) {
        console.log("s" + s + " value:", computeValue(s));
    }
}

function computeValue(stateId) {

    // base case
    if (stateId === finalStateId) {
        return 0;
    } 

    let links = [];

    dataset.edges.forEach(edge => {
        if (edge.source === stateId) {
            links.push(edge);
        }
    })

    let expected = 0;
    for (let i = 0; i < links.length; i++) {
        expected += links[i].prob * (links[i].reward + gamma * computeValue(links[i].target));
    }

    return expected;
}

/* estimating from data */
console.log("\n");
/* **** ** *** *** ***** */

let episodes = [
    [ 
        {id: 0, reward: 1},
        {id: 2, reward: 0}, 
        {id: 3, reward: 1}, 
        {id: 5, reward: 0},          
    ],
    [
        {id: 0, reward: 1}, 
        {id: 2, reward: 0}, 
        {id: 4, reward: 10}, 
        {id: 5, reward: 0},         
    ],
    [
        {id: 0, reward: 1},
        {id: 2, reward: 0},
        {id: 3, reward: 1},
        {id: 5, reward: 0}
    ],
    [
        {id: 0, reward: 1},
        {id: 2, reward: 0},
        {id: 3, reward: 1},
        {id: 5, reward: 0},        
    ]
];

// keep the previous value estimations
let experience = [];
for (let i = 0; i < counterId; i++) {
    experience.push({ avg: 0, n: 0});
}

estimateValueFromData();

function estimateValueFromData() {
    let maxEpisodes = 4;
    let totalReward = 0;

    for (let i = 0; i < maxEpisodes; i++) {

        // long way
        let value = computeValueFromData(episodes[i], 0);
        //console.log("Exp episode " + (i+1) + ":", Object.assign([], experience));
        console.log("V(0), episode " + (i+1) + ":", value);

        // short way
        for (j = 0; j < episodes[i].length; j++) {
            // sum all reward of a sequence:
            totalReward += episodes[i][j].reward;
        }
    }

    let result = totalReward / episodes.length;
    console.log("\nV(0) for all episodes is: ", result);
}

function computeValueFromData(sequence, index) {
    let state = sequence[index];

    if (state.id === finalStateId) {
        return 0;
    }

    index++;
    let nextStateId = sequence[index].id;
    
    // update experience
    let nextValue = computeValueFromData(sequence, index);
    let currExp = experience[nextStateId];

    //console.log("update exp s" + nextStateId, currExp, nextValue);
    currExp.n++;
    currExp.avg = currExp.avg + (nextValue - currExp.avg) / currExp.n;
    
    return state.reward + gamma * currExp.avg;
}

/* ******************* */
// Why TD(1) is wrong
/* ******************* */

// NB state start from 0.
let episodeTrans = [
    [ 
        // Transaction S_t-1 to S-t with reward
        {from: 0, reward: 1, to: 2},
        {from: 2, reward: 0, to: 3}, 
        {from: 3, reward: 1, to: 5}          
    ],
    [
        {from: 0, reward: 1, to: 2}, 
        {from: 2, reward: 0, to: 4}, 
        {from: 4, reward: 10, to: 5}    
    ],
    [
        {from: 0, reward: 1, to: 2},
        {from: 2, reward: 0, to: 3},
        {from: 3, reward: 1, to: 5}
    ],
    [
        {from: 0, reward: 1, to: 2},
        {from: 2, reward: 0, to: 3},
        {from: 3, reward: 1, to: 5}   
    ],
    [
        {from: 1, reward: 2, to: 2},
        {from: 2, reward: 0, to: 4},
        {from: 4, reward: 10, to: 5}
    ]
];

temporalDifference(episodeTrans, 1);

function temporalDifference(episodes, lambda) {
    let alpha = 1;  // learning rate
    let gamma = 1;  // discounted factor

    // 2-dim array: save V of episodes of state
    let values = []; 

    values.push([]) // init first values to 0
    for (let i = 0; i < totalStates; i++) {
        values[0].push(0);    // init V for each state
    }
    
    for (let epIndex = 0; epIndex < episodes.length; epIndex++) {
        let episode = episodes[epIndex];
        
        let eligibility = [];
        for (let i = 0; i < totalStates; i++) {
            eligibility.push(0);
        }

        values.push([]);
        for (let i = 0; i < totalStates; i++) {
            // init V for each state
            values[epIndex + 1].push(values[epIndex][i]);
        }
        let currV = values[epIndex + 1];

        // for each transition
        for (let t = 0; t < episode.length; t++) {
            let transition = episode[t];

            let fromState = transition.from;
            let toState = transition.to;
            let reward = transition.reward;

            eligibility[fromState]++;

            // temporal difference is equal to any state
            let tempDiff = reward + 
                gamma * (currV[toState] - currV[fromState]);

            // for each state
            for (let s = 0; s < totalStates; s++) {
                currV[s] = currV[s] + alpha * tempDiff * eligibility[s];
                eligibility[s] = lambda * gamma * eligibility[s];
            }
        }

        console.log("V_" + epIndex + "(s)", currV);
    }

    //console.log("Estimated V = ", values);
}


</script>
        
        
</body>

</html>